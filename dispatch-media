#!/usr/bin/python3
# Copyright 2010 Quantique. Licence: GPL3+
# ~/bin/dispatch-media

"""
Send downloaded media to its rightful place, according to its nature.

This script looks for downloaded archives and torrents.
See dispatch-media.conf for configuring it.


Dependencies (some could be made optional):
- python3-libtorrent (reading .torrent files)
- python3-yaml (configuration)
- python3-xattr (extended attributes, for not revisiting files twice)
- p7zip-full (listing many archives)
- dtrx (extracting archives)
- rsync (efficient copying)
Non-free:
- p7zip-rar (listing rar archives)
- unrar (extracting rar archives)

TODO:
    Support relocating torrents.
    This is client-specific and could be done with specialized sources.
    For example, rtorrent stores paths in enriched torrent files
    in its session directory.

    Keep timestamps. Or at least, loop through files in timestamp order.

    A special mode for single-file torrents. eg, music -> tracks.
"""

import dispatchmedia.classify as CL
from dispatchmedia.common import iso8601_now, ensure_dir, memoized_property
from dispatchmedia.torrents import TorrentFileError
from dispatchmedia.media_types import Media, Unknown, Empty, Archive
from dispatchmedia.xmlrpc2scgi import do_xmlrpc

import contextlib
import errno
import glob
import hashlib
import logging
import optparse
import os
import os.path
import re
import shutil
import subprocess
import sys
import xattr
import yaml


LOGGER = logging.getLogger(__name__)
DEFAULT_CONF = '~/.config/dispatch-media.conf'


def link_once(orig, dest, symbolic):
    if symbolic:
        # The samefile test won't work for broken yet correct symlinks
        orig_rel = os.path.relpath(orig, os.path.dirname(dest))
        if os.path.islink(dest) and os.readlink(dest) == orig_rel:
            return
    else:
        orig_rel = None

    if os.path.lexists(dest):
        if not os.path.exists(dest):
            LOGGER.warning(
                    '%s already exists and is a broken symlink, skipping',
                    dest)
        elif not os.path.samefile(orig, dest):
            LOGGER.warning(
                    '%s already exists and doesn\'t point to %s %s %s, skipping',
                    dest, orig, orig_rel, symbolic)
        return

    if symbolic:
        os.symlink(orig_rel, dest)
    else:
        try:
            os.link(orig, dest)
        except OSError as e:
            if e.errno != errno.EPERM:
                raise
            # chattr +i prevents hardlinking, sadly
            LOGGER.warning('%s linking %s to %s', e.strerror, orig, dest)


def link_deep(release, orig, dest, symbolic):
    """
    To delete a symlink tree:
        find \( -type l -o \( -type d -empty \) \) -delete
    """

    for (src, dest) in release.walk_lockstep(orig, dest):
        link_once(src, dest, symbolic)


def symlink_once(release, orig, dest):
    link_once(orig, dest, symbolic=True)


def symlink_deep(release, orig, dest):
    link_deep(release, orig, dest, symbolic=True)


def hardlink_deep(release, orig, dest):
    link_deep(release, orig, dest, symbolic=False)


def move_once(release, orig, dest):
    if os.path.lexists(dest):
        LOGGER.warning(
                '%s already exists, skipping move of %s',
                dest, orig)
        return
    # DWIM workaround: this works OK if dest doesn't exist
    shutil.move(orig, dest)


def rsync_once(release, orig, dest):
    # DWIM workaround
    if os.path.isdir(orig):
        orig += '/'
    subprocess.check_call(['rsync', '-ax', '--', orig, dest, ])


FS_ACTIONS = {
    'symlink-once': symlink_once,
    'symlink-deep': symlink_deep,
    'hardlink':     hardlink_deep,
    'rsync':        rsync_once,
    }

TORRENT_ACTIONS = dict(FS_ACTIONS)
RTORRENT_ACTIONS = dict(FS_ACTIONS)
DIR_ACTIONS = dict(move=move_once, **FS_ACTIONS)


STRIP_RAR_SUFFIX_RE = re.compile(r'(.*?)(\.part0*1)?\.rar$', re.I)
EXTRACT_BAK = 'extract-bak'
EXTRACT_LOG = 'extract-log'


class RarRelease(object):
    def __init__(self,
            parent, archive_name, short_name, archive_files, aux_files):
        self.parent = parent
        self.archive_name = archive_name
        self.short_name = short_name
        self.archive_files = archive_files
        self.aux_files = aux_files

    def path(self, name):
        return os.path.join(self.parent, name)

    def aux_name(self, suffix):
        return self.short_name + '.' + suffix

    def aux_path(self, suffix):
        return self.path(self.aux_name(suffix))

    @property
    def archive_path(self):
        return self.path(self.archive_name)


def iter_rar_releases(basedir, depth):
    # Path vs options. '-(!' are unsafe.
    if not os.path.isabs(basedir):
        basedir = './' + basedir

    # Find single-part archives and first parts of multi-part archives.
    cmd = ['find', '-H', basedir,
        '-maxdepth', str(depth),
        '-iname', '*.' + EXTRACT_BAK, '-prune',
        '-o', '(',
            '-type', 'f',
            '-iname', '?*.rar',
            '-a', '(',
                '-iregex', '.*\.part0*1\.rar$',
                '-o', '!', '-iregex', '.*\.part[0-9]+.rar$',
                ')',
            ')', '-print',
        ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)

    for line in proc.stdout:
        archive_path = line.rstrip()
        prefix, part = STRIP_RAR_SUFFIX_RE.match(archive_path).groups()
        parent, pfx_name = os.path.split(prefix)
        parent1, archive_name = os.path.split(archive_path)
        assert parent == parent1

        if part:  # multipart archive
            archive_files_re = re.compile('^' + re.escape(pfx_name)
                    + '\\' + part.replace('0', '[0-9]').replace('1', '[0-9]')
                    + '\.rar$', re.I)
        else:  # might yet be the .r00 kind of multipart.
            archive_files_re = re.compile('^' +
                    re.escape(archive_name[:-2]) + '(ar|[0-9]{2})$', re.I)
        aux_files_re = re.compile('^' + re.escape(pfx_name) + '.*$', re.I)
        aux_files = set(fname
                for fname in os.listdir(parent)
                if aux_files_re.match(fname))
        archive_files = set(fname
                for fname in aux_files if archive_files_re.match(fname))
        aux_files.difference_update(archive_files)

        rr = RarRelease(parent, archive_name, pfx_name,
                archive_files, aux_files)
        yield rr

    proc.wait()
    if proc.returncode != 0:
        raise subprocess.CalledProcessError(cmd, proc.returncode)


def extract_archive(rr, dest_parent, move_archive_on_success=True):
    logname = rr.aux_name(EXTRACT_LOG)

    # This check is necessary since we don't always move to EXTRACT_BAK,
    # for the evil people who torrent archives.
    # The log is only created on success, so an existence check is enough.
    if logname in rr.aux_files:
        LOGGER.info('Archive %s has already been extracted, skipping',
                rr.archive_path)
        return

    # List the files so we know where they were extracted.
    cmd = ['dtrx', '-nv', '--', os.path.abspath(rr.archive_path), ]
    proc = subprocess.Popen(cmd,
            cwd=dest_parent, stdout=subprocess.PIPE, text=True)

    line = next(proc.stdout)
    dtrx_dest = os.path.normpath(line.rstrip())
    if os.path.sep in dtrx_dest:
        dtrx_dest = dtrx_dest[:dtrx_dest.index(os.path.sep)]
    dtrx_dest = os.path.join(dest_parent, dtrx_dest)

    proc.wait()
    if proc.returncode != 0:
        raise subprocess.CalledProcessError(cmd, proc.returncode)

    with open(rr.path(logname), 'a') as log:
        yaml.dump(
                [{'extracted-to': dtrx_dest, 'date': iso8601_now(), }],
                log, default_flow_style=False)

    if not move_archive_on_success:
        return
    extract_bak = rr.aux_path(EXTRACT_BAK)
    ensure_dir(extract_bak)
    for part in rr.archive_files:
        os.rename(rr.path(part), os.path.join(extract_bak, part))


# Not the same prototype as TORRENT_ACTIONS!
# Takes an extra move_archive_on_success keyword argument
ARCHIVE_ACTIONS = {
    'extract': extract_archive,
    }


class Places(object):
    def __init__(self, places_config):
        lowercase = places_config['lowercase']
        pluralize = places_config['pluralize']

        accepted = places_config['accept']
        accepted = set(Media.registry[cat] for cat in accepted)

        basedir = os.path.expanduser(places_config['basedir'])
        self.locations = {}

        for cat in accepted:
            name = cat.name(lower=lowercase, plural=pluralize)
            if name in places_config:
                loc = os.path.expanduser(places_config[name])
            else:
                loc = name
            loc = os.path.join(basedir, loc)
            self.locations[cat] = loc

        self.autocreate = places_config['autocreate']

    def dest_base_of_cat(self, cat, release):
        if cat not in self.locations:
            # Not an accepted category, see the places.accept setting
            LOGGER.info('Skipping %s %s', cat.name(lower=True), release)
            return
        dest_parent = self.locations[cat]
        if not os.path.exists(dest_parent):
            if self.autocreate:
                LOGGER.info('Creating %s', dest_parent)
                os.makedirs(dest_parent, mode=0o700)
            else:
                LOGGER.warning('Skipping %s, please create %s',
                        release, dest_parent)
                return
        return dest_parent


class DispatchHelper(object):
    def __init__(self, source_config, places, db_path):
        self.__source_config = source_config
        self.__places = places
        self.__db_path = db_path

    def lookup_cat(self, release):
        cat = lookup_cat(release)
        if cat:
            return self.__places.dest_base_of_cat(cat, release)

    def filter_items(self, item_iter, item_key=lambda x: x):
        class Callbacks(object):
            def __init__(self, key):
                self.key = key
            def done(self):
                db[self.key] = '1'

        for item in item_iter:
            key = 'done:%s:%s' % (self._source_hash, item_key(item))
            if key in db:
                continue
            yield item, Callbacks(key)

    @memoized_property
    def _source_hash(self):
        return hashlib.sha1(yaml.safe_dump(self.__source_config))

    @memoized_property
    def _db(self):
        return dbm.open(self.__db_path, 'c')

    @contextlib.contextmanager
    def filter_callback(self, key):
        class Callbacks(object):
            def __init__(self, key):
                self.key = key
            def done(self):
                self._db[self.key] = '1'

        key = 'done:%s:%s' % (self._source_hash, key)
        if key in self._db:
            return
        yield Callbacks(key)


def lookup_cat(release):
    try:
        cat = CL.classify(release)
    except subprocess.CalledProcessError as e:
        LOGGER.warning(e)
        return
    except TorrentFileError as e:
        LOGGER.warning(e)
        # Some errors don't name the release, do so
        LOGGER.warning('Skipping torrent %s', release)
        return
    except UnicodeDecodeError as e:
        LOGGER.info(e)
        LOGGER.warning(
            'Skipping torrent with bad character encoding %s', release)
        return

    if cat in (Unknown, Empty):
        LOGGER.info('Skipping %s %s', cat.name(lower=True), release)
        return

    if cat is Archive:
        if release.is_indirect:
            LOGGER.info(
                'Skipping nested archive referenced by %s', release)
        else:
            LOGGER.info('Skipping nested archive inside %s', release)
        return

    return cat


def dispatch_torrents(source_config, helper):
    pattern = os.path.expanduser(source_config['pattern'])
    down_base = os.path.expanduser(source_config['download'])
    if not os.path.exists(down_base):
        LOGGER.error(
                'Download directory %s doesn\'t exist', down_base)
        return
    action = TORRENT_ACTIONS[source_config['action']]

    for torrent, cb in helper.filter_items(glob.iglob(pattern)):
        try:
            release = CL.Torrent(torrent)
        except TorrentFileError as err:
            LOGGER.error(err)
            continue

        dest_parent = helper.lookup_cat(release)
        if dest_parent is None:
            continue
        down_loc = os.path.join(down_base, release.likely_down_name)
        action(release, down_loc, dest_parent)
        cb.done()


def dispatch_rtorrent(source_config, helper):
    endpoint = os.path.expanduser(source_config['endpoint'])
    action = RTORRENT_ACTIONS[source_config['action']]
    session_dir = do_xmlrpc(endpoint, 'session.path')
    exclusions = [os.path.normpath(os.path.expanduser(ex)) + '/' for ex in source_config['exclude']]

    for (info_hash, down_loc, fname, fname2, dname, dname2) in do_xmlrpc(
        endpoint, 'd.multicall2', '', 'complete',
        'd.hash=', 'd.base_path=',
        'd.loaded_file=', 'd.tied_to_file=',
        'd.directory=', 'd.directory_base=',
    ):
        if not down_loc:
            assert dname, info_hash
            down_loc = dname
        if not fname:
            if fname2:
                # Happens with .meta files, though that seems to be
                # rectified once rtorrent is restarted.
                # These need a different loader, either from the .meta
                # or from the rtorrent API.
                fname = fname2
            else:
                fname = os.path.join(session_dir, info_hash + '.torrent')
        fname = os.path.expanduser(fname)
        fattr = xattr.xattr(fname)
        done_xattr_key = ('user.dispatch.rtorrent.%s' % info_hash).encode()
        try:
            done = fattr.get(done_xattr_key)
            del done
        except IOError:
            pass
        else:
            #pass
            continue
        release = CL.RTorrentTorrent(fname, endpoint, info_hash)
        dest_parent = helper.lookup_cat(release)
        if dest_parent is None:
            continue
        #LOGGER.warning('down_loc %r %r', down_loc, dest_parent)
        if not down_loc:
            LOGGER.warning('Empty d.base_path: %r', info_hash)
            continue
        if any(down_loc.startswith(ex) for ex in exclusions):
            LOGGER.warning('Excluded down_loc %r', down_loc)
        else:
            action(release, down_loc, dest_parent)
        # The xattr value isn't the dest, because actions
        # are mostly working with dest_parent and haven't
        # been converted.
        try:
            fattr.set(done_xattr_key, b'ok')
        except IOError as e:
            if e.errno == errno.ENOENT:
                LOGGER.warning('Torrent file doesn\'t exist: %s', info_hash)
            else:
                raise


def dispatch_transmission(source_config, helper):
    # XXX Not tested yet
    confdir = os.path.expanduser(source_config['confdir'])
    if not os.path.exists(confdir):
        LOGGER.error(
                'Transmission configuration directory %s doesn\'t exist',
                confdir)
        return
    action = TORRENT_ACTIONS[source_config['action']]

    tdir = os.path.join(confdir, 'torrents')
    for tbasename in os.listdir(tdir):
        fname = os.path.join(tdir, tbasename)
        release = CL.TransmissionTorrent(fname, confdir)

        dest_parent = helper.lookup_cat(release)
        if dest_parent is None:
            continue
        down_loc = release.transmission_down_loc
        LOGGER.info('Transmission download at %s', down_loc)
        action(release, down_loc, dest_parent)


def dispatch_directories(source_config, helper):
    pattern = os.path.expanduser(source_config['pattern'])
    action = DIR_ACTIONS[source_config['action']]
    for dname in glob.iglob(pattern):
        release = CL.Directory(dname)
        dest_parent = helper.lookup_cat(release)
        if dest_parent is None:
            continue
        action(release, dname, dest_parent)


def dispatch_archives(archives_config, helper):
    search_base = os.path.expanduser(archives_config['search'])
    if not os.path.exists(search_base):
        LOGGER.error(
                'Archives directory %s doesn\'t exist', search_base)
        return
    depth = archives_config['depth']
    action = ARCHIVE_ACTIONS[archives_config['action']]
    move_archive_on_success = archives_config['move-extracted']

    for rr in iter_rar_releases(search_base, depth):
        release = CL.Archive(rr.archive_path)
        dest_parent = helper.lookup_cat(release)
        if dest_parent is None:
            continue
        action(rr, dest_parent,
                move_archive_on_success=move_archive_on_success)


def main():
    parser = optparse.OptionParser()
    parser.add_option('-v', '--verbose',
            action='count',
            dest='verbosity',
            default=0,
            help='Increase verbosity',
            )

    parser.add_option('--config',
            help='Load configuration from CONFIG instead of %s' % DEFAULT_CONF,
            )

    (options, args) = parser.parse_args()
    # WARNING, INFO, DEBUG
    log_level = logging.WARNING - 10 * options.verbosity
    logging.basicConfig(level=log_level, format='%(levelname)s: %(message)s')
    CL.LOGGER.level = log_level + 10

    if options.config is None:
        options.config = os.path.expanduser(DEFAULT_CONF)

    if args:
        parser.print_help()
        return 2

    try:
        with open(options.config) as confstream:
            config = yaml.safe_load(confstream)
    except IOError as err:
        LOGGER.error('Configuration file %s couldn\'t be loaded, exiting',
                options.config)
        return 3

    places = Places(config['places'])

    for source in config['sources']:
        helper = DispatchHelper(source, places, '/FIXME')
        stype = source['type']
        if not source.get('enable', True):
            LOGGER.info('Skipping disabled %s source', stype)
            continue
        if stype == 'archives':
            dispatch_archives(source, helper)
        elif stype == 'torrents':
            dispatch_torrents(source, helper)
        elif stype == 'directories':
            dispatch_directories(source, helper)
        elif stype == 'rtorrent':
            dispatch_rtorrent(source, helper)
        elif stype == 'transmission':
            dispatch_transmission(source, helper)
        else:
            LOGGER.error('Invalid source type %s', stype)

if __name__ == '__main__':
    sys.exit(main())

